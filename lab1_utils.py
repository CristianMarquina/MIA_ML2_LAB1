import math
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

from collections import deque
from sklearn.metrics import mean_absolute_error

# Online Libraries (River)
from river import base, drift


def plot_predictions(model, X_scaled, y_real, df, set_name, model_name='Model', filename=None):
    y_pred = model.predict(X_scaled)
    mae = mean_absolute_error(y_real, y_pred)
    dates = pd.to_datetime(df.loc[y_real.index, 'Date'])

    fig, ax = plt.subplots(figsize=(14, 5))
    ax.plot(dates, y_real.values, label='Real (Target High)', color='steelblue', linewidth=1.5)
    ax.plot(dates, y_pred,        label=f'{model_name} Prediction', color='tomato', linewidth=1.5, linestyle='--')

    ax.set_title(f'{model_name}: Real vs Predicted ({set_name} Set)\nMAE: {mae:.4f}')
    ax.set_xlabel('Date')
    ax.set_ylabel('Price (USD)')
    ax.legend()
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))
    plt.xticks(rotation=45)
    plt.tight_layout()

    if filename is not None:
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"Plot saved as '{filename}'")
    
    plt.show()

    return mae


def plot_predictions_LPM(y_real, y_pred, date_index, df, set_name, model_name='LPM', filename=None):
    """
    Plot real vs predicted values for LPM models.
    Uses date_index (pandas Index) to look up dates from the global df.
    """
    mae = mean_absolute_error(y_real, y_pred)
    dates = pd.to_datetime(df.loc[date_index, 'Date'])

    fig, ax = plt.subplots(figsize=(14, 5))
    ax.plot(dates.values, y_real, label='Real (Target High)', color='steelblue', linewidth=1.5)
    ax.plot(dates.values, y_pred, label=f'{model_name} Prediction', color='tomato', linewidth=1.5, linestyle='--')

    ax.set_title(f'{model_name}: Real vs Predicted ({set_name} Set)\nMAE: {mae:.4f}')
    ax.set_xlabel('Date')
    ax.set_ylabel('Price (USD)')
    ax.legend()
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))
    plt.xticks(rotation=45)
    plt.tight_layout()

    if filename is not None:
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"Plot saved as '{filename}'")
    
    plt.show()

    return mae


# --- Function to generate BATCH Features (Pandas) ---
def get_batch_features_and_target(df_in):
    """
    Calculates the same metrics as the River class but vectorized using Pandas.
    """
    df_temp = df_in.copy()
    
    # Return: (Current Close Price - Previous Close Price) / Previous Close Price
    df_temp['Return'] = df_temp['Close'].pct_change()
    
    # Rolling Means (Windows 5 and 20)
    df_temp['Mean_return_5'] = df_temp['Return'].rolling(window=5).mean()
    df_temp['Mean_return_20'] = df_temp['Return'].rolling(window=20).mean()
    
    # Volatility (Window 20 std)
    # IMPORTANT: ddof=0 to match the population standard deviation formula used in the River class
    df_temp['Volatility_20'] = df_temp['Return'].rolling(window=20).std(ddof=0)
    
    # Open-Close Difference
    df_temp['Open_Close_Diff'] = df_temp['Close'] - df_temp['Open']
    
    # Volume Deviation (Current Volume - Average Volume of last 20 days)
    df_temp['Volume_dev'] = df_temp['Volume'] - df_temp['Volume'].rolling(window=20).mean()
    
    # Remove rows with NaNs generated by rolling windows (the first 20 rows)
    df_temp = df_temp.dropna()
    
    # Separate X (Features) and y (Target)
    features = ['Close', 'Return', 'Mean_return_5', 'Mean_return_20', 
                'Volatility_20', 'Open_Close_Diff', 'Volume', 'Volume_dev']
    
    
    X = df_temp[features]
    y = df_temp['Target_High']
    
    return X, y


def analyze_and_plot_drift_batch(model, X_scaled, y_real, df, set_name, model_name='Batch Model', filename=None):
    """
    Calculates predictions for a batch model, computes the sequential absolute error, 
    and uses ADWIN and Page-Hinkley to detect concept drift.
    Optionally saves the plot to a file.
    """
    print(f"\n--- Analyzing Concept Drift for {model_name} ({set_name} Set) ---")
    
    # 1. Get predictions and align dates (Same logic as your plot_predictions)
    y_pred = model.predict(X_scaled)

    # If predictions are in shape (N, 1) like in Keras, flatten them to (N,) -- necessary for the MLP model
    if hasattr(y_pred, 'flatten'):
        y_pred = y_pred.flatten()

    dates = pd.to_datetime(df.loc[y_real.index, 'Date']).values
    y_real_vals = y_real.values
    
    # 2. Initialize detectors
    adwin = drift.ADWIN()
    ph = drift.PageHinkley()
    
    errors = []
    adwin_drifts = []
    ph_drifts = []
    
    # 3. Feed the error stream sequentially to the detectors
    # Even though it's a batch model, we evaluate its errors chronologically
    for i in range(len(y_real_vals)):
        error = abs(y_real_vals[i] - y_pred[i])
        errors.append(error)
        
        # Update detectors
        adwin.update(error)
        ph.update(error)
        
        # Check for drift and save the EXACT DATE it happened
        if adwin.drift_detected:
            adwin_drifts.append(dates[i])
        if ph.drift_detected:
            ph_drifts.append(dates[i])
            
    print(f"ADWIN detected {len(adwin_drifts)} drift points.")
    print(f"Page-Hinkley detected {len(ph_drifts)} drift points.")
    
    # 4. Plotting
    fig, ax = plt.subplots(figsize=(14, 5))
    
    # Plot raw errors
    ax.plot(dates, errors, label='Absolute Error', color='lightgray', linewidth=1)
    
    # Plot moving average of errors to see the trend
    error_series = pd.Series(errors)
    ax.plot(dates, error_series.rolling(10).mean(), label='Error Moving Average (10)', color='blue', linewidth=1.5)
    
    # Plot ADWIN drifts (Red dashed lines)
    for i, d in enumerate(adwin_drifts):
        ax.axvline(x=d, color='red', linestyle='--', alpha=0.6, label='ADWIN Drift' if i == 0 else "")
        
    # Plot Page-Hinkley drifts (Green dotted lines)
    for i, d in enumerate(ph_drifts):
        ax.axvline(x=d, color='green', linestyle=':', alpha=0.8, label='Page-Hinkley Drift' if i == 0 else "")
        
    ax.set_title(f'Concept Drift Detection on Absolute Error\n{model_name} ({set_name} Set)')
    ax.set_xlabel('Date')
    ax.set_ylabel('Absolute Error (USD)')
    ax.legend()
    
    # Date formatting (Same as your plotting function)
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))
    plt.xticks(rotation=45)
    plt.tight_layout()
    
    if filename is not None:
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"Plot saved as '{filename}'")
    
    plt.show()
    
    return adwin_drifts, ph_drifts


# --- Class for ONLINE Features (River) ---
class OnlineSPYFeatures(base.Transformer):

    def __init__(self):
        self.prev_close = None
        
        self.window_5 = deque(maxlen=5)
        self.window_20 = deque(maxlen=20)
        self.volume_window_20 = deque(maxlen=20)

    def mean(self, window):
        return sum(window) / len(window) if window else 0.0

    def std(self, window):
        if len(window) < 2:
            return 0.0
        m = self.mean(window)
        return math.sqrt(sum((x - m) ** 2 for x in window) / len(window))

    def transform_one(self, x):

        close = x["Close"]
        volume = x["Volume"]
        open_ = x["Open"]

        # Compute return
        if self.prev_close is not None:
            ret = (close - self.prev_close) / self.prev_close
        else:
            ret = 0.0

        # Update rolling windows
        self.window_5.append(ret)
        self.window_20.append(ret)
        self.volume_window_20.append(volume)

        features = {
            "Close": close,
            "Return": ret,
            "Mean_return_5": self.mean(self.window_5),
            "Mean_return_20": self.mean(self.window_20),
            "Volatility_20": self.std(self.window_20),
            "Open_Close_Diff": close - open_,
            "Volume": volume,
            "Volume_dev": volume - self.mean(self.volume_window_20),
        }

        self.prev_close = close

        return features
    

def plot_predictions_online(records, set_name, model_name='Online Model', filename=None):
    """Plot real vs predicted values for online models using the records list."""
    df_plot = pd.DataFrame(records)
    df_plot['date'] = pd.to_datetime(df_plot['date'])
    mae = mean_absolute_error(df_plot['y_real'], df_plot['y_pred'])

    fig, ax = plt.subplots(figsize=(14, 5))
    ax.plot(df_plot['date'], df_plot['y_real'], label='Real (Target High)', color='steelblue', linewidth=1.5)
    ax.plot(df_plot['date'], df_plot['y_pred'], label=f'{model_name} Prediction', color='tomato', linewidth=1.5, linestyle='--')

    ax.set_title(f'{model_name}: Real vs Predicted ({set_name} Set)\nMAE: {mae:.4f}')
    ax.set_xlabel('Date')
    ax.set_ylabel('Price (USD)')
    ax.legend()
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))
    plt.xticks(rotation=45)
    plt.tight_layout()

    if filename is not None:
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"Plot saved as '{filename}'")
    
    plt.show()

    return mae


def analyze_and_plot_drift_online(records, model_name="Model", filename=None):
    """
    Takes a list of prediction records (dictionaries with 'date', 'y_real', 'y_pred')
    calculates the absolute error stream, and uses ADWIN and Page-Hinkley to detect drift.
    Optionally saves the plot to a file.
    """
    print(f"\n--- Analyzing Concept Drift for {model_name} ---")
    
    # Initialize detectors
    adwin = drift.ADWIN()
    ph = drift.PageHinkley()
    
    errors = []
    dates = []
    
    adwin_drifts = []
    ph_drifts = []
    
    # 1. Feed the error stream to the detectors
    for record in records:
        # Calculate Absolute Error
        error = abs(record['y_real'] - record['y_pred'])
        errors.append(error)
        
        # Convert to pandas datetime
        current_date = pd.to_datetime(record['date'])
        dates.append(current_date)
        
        # Update detectors
        adwin.update(error)
        ph.update(error)
        
        # Check for drift and save the EXACT DATE it happened
        if adwin.drift_detected:
            adwin_drifts.append(current_date)
        if ph.drift_detected:
            ph_drifts.append(current_date)
            
    print(f"ADWIN detected {len(adwin_drifts)} drift points.")
    print(f"Page-Hinkley detected {len(ph_drifts)} drift points.")
    
    # 2. Plotting the Error Stream and Drift Points
    fig, ax = plt.subplots(figsize=(14, 5))
    
    # Plot raw errors using the dates for the X-axis
    ax.plot(dates, errors, label='Absolute Error', color='lightgray', linewidth=1)
    
    # Add a moving average to make the error trend easier to see
    error_series = pd.Series(errors)
    ax.plot(dates, error_series.rolling(10).mean(), label='Error Moving Average (10)', color='blue', linewidth=1.5)
    
    # Plot ADWIN drifts
    for i, d in enumerate(adwin_drifts):
        ax.axvline(x=d, color='red', linestyle='--', alpha=0.6, label='ADWIN Drift' if i == 0 else "")
        
    # Plot Page-Hinkley drifts
    for i, d in enumerate(ph_drifts):
        ax.axvline(x=d, color='green', linestyle=':', alpha=0.8, label='Page-Hinkley Drift' if i == 0 else "")
        
    ax.set_title(f"Concept Drift Detection on Absolute Error ({model_name})")
    ax.set_xlabel("Date")
    ax.set_ylabel("Absolute Error (USD)")
    ax.legend()
    
    # Date formatting (Same logic as plot_predictions)
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))
    plt.xticks(rotation=45)
    
    plt.tight_layout()
    
    if filename is not None:
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"Plot saved as '{filename}'")
    
    plt.show()
    
    return adwin_drifts, ph_drifts